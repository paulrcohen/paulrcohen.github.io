<title>Editorial, AIJ</title>

<p>

<i>Artificial Intelligence</i> publishes theoretical, analytical, 
"neat" articles, and relatively little empirical research.  At the 
invitation of the Editor in Chief, Daniel Bobrow, we are trying to change 
this.  Several factors probably account for the lack of empirical work in 
the pages of the Journal.  If by empirical one means careful observation in 
informative conditions, probing results and forming interpretations of 
data, and testing these interpretations prospectively, then empirical work 
is rare in Artificial Intelligence.  It tends to be done in subfields that 
have the technology to support it; for instance, the avilability of online 
corpora has changed the methodology of natural language research 
dramatically.  Inevitably, productive areas of Artificial Intelligence 
start their own journals, so many first-rate empirical articles are never 
submitted to the journal <i>Artificial Intelligence</i>.  Finally, there is the 
perception that 
empirical work is unwelcome here.  This special issue is intended to 
correct this erroneous impression and prime the pump with eleven excellent 
and unabashedly empirical articles.  We encourage all researchers to read 
and enjoy, and then submit their own empirical research to the journal.

<p>
The papers in this issue are in many ways representative of the state of 
empirical AI research.  Five papers deal with natural language, a 
particularly hot area that has been revitalized by corpus-based statistical 
methods.  Three papers come from the machine learning community (and one 
more was written by researcher in this community), which has a strong 
empirical methodology.  It is not surprising but perhaps a little 
disappointing that such a large proportion of the papers came from areas of 
AI where empirical work is the norm.  But happily, some of these articles 
push the methodological envelope; they don't merely represent business as 
usual in natural language and machine learning.  For example, Whitley, Rana, Dzubera and 
Mathias 
develops a suite of test problems with carefully controlled characteristics 
for genetic algorithms; Segre, Gordon and Elkan present a method for 
modeling the performance of machine learning algorithms; and Cooper, Fox,
Farrington and Shallice show 
how to model complex AI systems (e.g., SOAR) with executable 
specifications.  These articles are surely in the methodological vanguard.  
We may chart the evolution of empirical methods as follows:  First we learn 
to measure performance, then we learn to test hypotheses, and then we learn 
how to build concise, predictive, sometimes explanatory models of our 
systems.  Much AI research hasn't yet reached the first stage of measuring 
performance, so we must view all of the papers in this volume as 
illustrative and some as leading us into an exciting empirical landscape.
We look forward to seeing more work of this caliber and orientation in 
<i>Artificial Intelligence</i> in future.

<p>
Paul Cohen and Bruce Porter<br>

<p>
<i>Artificial Intelligence</i>, Vol. 85, Nos. 1-2, pp. 1-2, August 1996.

